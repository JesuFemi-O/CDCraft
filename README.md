# CDCraft - Postgresql CDC Simulation Engine

Simulate real-world Change Data Capture (CDC) activity on a PostgreSQL table with evolving schema, inserts, updates, and deletes. This tool is perfect for testing streaming pipelines, Debezium connectors, or building end-to-end CDC systems.

---

## ğŸš€ Features

- âœ… Generate and insert realistic fake records into a PostgreSQL table
- ğŸ” Randomly update and delete existing rows
- ğŸ“¦ Optionally evolve schema over time (add/drop columns)
- ğŸ§¾ Interactive setup for schema, table, publication, and replication slot
- ğŸ”’ Option to disable schema evolution and focus purely on inserts, updates, and deletes
- ğŸ’¥ Graceful `Ctrl+C` handling with final summary and cleanup prompt

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â””â”€â”€ src
    â”œâ”€â”€ batch_generator.py
    â”œâ”€â”€ cli.py
    â”œâ”€â”€ column_manager.py
    â”œâ”€â”€ column_pool.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ mutation_engine.py
    â”œâ”€â”€ prompt_utils.py
    â”œâ”€â”€ runner.py
    â””â”€â”€ schema_manager.py
```

---

## ğŸ”§ Setup with `uv`

This project uses [`uv`](https://github.com/astral-sh/uv) â€” a fast, modern Python package manager.

### âœ… 1. Install `uv`

```bash
curl -Ls https://astral.sh/uv/install.sh | sh
```

Or with Homebrew:

```bash
brew install astral-sh/uv/uv
```

### âœ… 2. Install dependencies and activate the virtual environment

```bash
uv venv              # Creates a .venv folder
source .venv/bin/activate

uv sync   # Install locked dependencies

OR...

uv pip install -r requirments.txt

OR...

pip install -r requirments.txt
```

### âœ… 3. Run the simulation

```bash
python src/main.py
```

---

## âš™ï¸ Configuration Options

You can use environment variables or a `.env` file to customize behavior.

| Env Var             | Description                                      | Default      |
|---------------------|--------------------------------------------------|--------------|
| `PGHOST`            | Hostname for PostgreSQL                         | `localhost`  |
| `PGDATABASE`        | PostgreSQL database name                        | `cdc_test`   |
| `PGUSER`            | PostgreSQL user                                 | `postgres`   |
| `PGPASSWORD`        | PostgreSQL password                             | `postgres`   |
| `PGPORT`            | PostgreSQL port                                 | `5432`       |
| `PGSCHEMA`          | Schema name to use                              | `public`     |
| `SKIP_SETUP`        | If `true`, skips interactive setup              | `false`      |
| `ENABLE_EVOLUTION`  | If `false`, disables schema evolution           | `true`       |

---

## ğŸ§ª Example: CDC with static schema

To simulate just inserts, updates, and deletes without schema changes:

```bash
ENABLE_EVOLUTION=false python src/main.py
```

---

## ğŸ“Š Output Example

```
ğŸš€ Starting CDC Simulation: 1000000 records in 2000 batches
ğŸ“¦ [Batch 25] Added column 'promo_code'
ğŸ—‘ï¸ [Batch 50] Dropped column 'discount_rate'
[Batch 100] Inserts: 50000, Updates: 25000, Deletes: 23000

ğŸ“Š CDC Simulation Complete!
Original Schema:
 - id: UUID
 - customer_name: TEXT
...

Schema Changes:
 - ADD: promo_code
 - DROP: discount_rate

Final Schema:
 - id: UUID
 - customer_name: TEXT
...

Schema Evolution Summary:
 - Additions: 3
 - Drops: 2
```

---

# CDCraft Example Pipeline

The example directory contains a fully reproducible CDC (Change Data Capture) demo pipeline built with Docker Compose.

Use it to spin up a ready-to-go stack: PostgreSQL, Kafka, Kafka Connect, MinIO, and more!

---

Quick Start

1. change directory:

```
cd CDCraft/example
```

2. Build the custom Kafka Connect image

Important: This project uses Docker Buildx to ensure cross-platform compatibility (e.g., running x86 images on Apple Silicon/M1).

You must build the Kafka Connect image before bringing up the stack!

```
make build-connect
```

3. Launch the stack:

```
make up
```


ğŸ› ï¸ Common Commands
	â€¢	Start the stack:
make up
	â€¢	Shut down & clean up:
make down
	â€¢	Tail logs:
make logs
	â€¢	Check available connector plugins:
make connect-plugins
	â€¢	Deploy connectors:
	â€¢	Source (Postgres): make pg-src
	â€¢	Sink (S3): make s3-sink
	â€¢	Open UIs:
	â€¢	MinIO: make minio-ui
	â€¢	Redpanda/Kafka Console: make console-ui

---

ğŸ§© Swap in Your Own Kafka Connect Image

By default, the stack uses the custom image built with make build-connect:

kafka-connect:
    image: cdcraft/kafka-connect:latest
    platform: linux/amd64
    ...

Feel free to use your own image (e.g., for dev or testing) by changing the image: line in docker-compose.yml.

---

âš¡ï¸ Notes
	â€¢	Why Buildx?
This enables you to build x86 images even if youâ€™re on ARM/M1 (Apple Silicon), avoiding weird platform errors.
	â€¢	Credentials & Endpoints:
The stack uses local, easy-to-change credentials for Postgres, MinIO, etc.
For production, always rotate/change these values.
	â€¢	Example Connectors:
Edit the connectors/source.json and connectors/sink.json files to fit your use case.

## ğŸ”„ Future Enhancements

- CLI support with argparse
- JSONL export for batch snapshots
- Integration with Kafka or S3
- Multi-table simulation

---

## ğŸ¤ Contributing

Built with â¤ï¸ by Emmanuel Ogunwede.
Open to ideas, contributions, and improvements!

